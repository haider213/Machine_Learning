{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Implementing the ideas in the Advanced Learning Algorithms>Week 1>Neural network layer**\n",
    "https://www.coursera.org/learn/advanced-learning-algorithms/lecture/z5sks/neural-network-layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python.eager.polymorphic_function'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [20], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\__init__.py:92\u001B[0m\n\u001B[0;32m     90\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackprop\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GradientTape\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcontext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m executing_eagerly\n\u001B[1;32m---> 92\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpolymorphic_function\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpolymorphic_function\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m function\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconstant_op\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m constant\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdevice_spec\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DeviceSpecV2 \u001B[38;5;28;01mas\u001B[39;00m DeviceSpec\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow.python.eager.polymorphic_function'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "A neuron outputs an activation which is equal to $a=g(z)$ where $z=wx+b$ where x is the input of the neuron and w and b are dependent on the training. The choice of $g$ function is dependedant on the training and kind of problem, in case of the sigmoid function $g(z)=1/e^(-z)$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def neuron(x,w,b):\n",
    "    a=w*x+b\n",
    "    a=1/(np.e**(-a)) #sigmoid function\n",
    "    return a\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def neuron_1(x, w, b):\n",
    "\n",
    "       a=w*x+b\n",
    "       a=1/(np.e**(-a))\n",
    "       return a #sigmoid function\n",
    "\n",
    "\n",
    "class Neural_Network_1:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.layers=None #layers should be a dict arranged as {layer_1: Number of Neurons,\n",
    "        #layer_2: Number of Neurons\n",
    "        #.\n",
    "        #.\n",
    "        #layer_n: Number of Neurons}\n",
    "\n",
    "        self.x=None\n",
    "        self.y=None\n",
    "        self.neuron=neuron_1()\n",
    "    def layer(self):\n",
    "        a=[[]]\n",
    "        i=1\n",
    "        for key in self.layers.keys:\n",
    "            number_of_neurons=self.layers(key)\n",
    "            if key==1:\n",
    "                for n in range(number_of_neurons):\n",
    "                    a[i,n]=neuron(self.x)\n",
    "\n",
    "\n",
    "\n",
    "                i=i+1\n",
    "            else:\n",
    "                for n in range(number_of_neurons):\n",
    "                    a[i,n]=neuron(self.a)\n",
    "\n",
    "        return a\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [15], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m3\u001B[39m):\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m4\u001B[39m):\n\u001B[1;32m----> 5\u001B[0m         \u001B[43ma\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43mj\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m=\u001B[39mi\u001B[38;5;241m*\u001B[39mj\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(x)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(a)\n",
      "\u001B[1;31mTypeError\u001B[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "x=[1,2,3,4]\n",
    "a=[[]]\n",
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "        a[i,j]=i*j\n",
    "print(x)\n",
    "print(a)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}